{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lenet_MNIST_Day6.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"7AYJYPJXcPxf","colab_type":"text"},"cell_type":"markdown","source":["**LeNet for MNIST Handwritten character recognition**\n"]},{"metadata":{"id":"CHYFQSt1bCaD","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9vT1rL7Rcr64","colab_type":"code","colab":{}},"cell_type":"code","source":["# Device configuration\n","# How to choose between CPU and GPU?\n","# Use torch.cuda.is_available() and torch.device() to assign the device (CPU/GPU) to a variable named device.   "],"execution_count":0,"outputs":[]},{"metadata":{"id":"eUwvBAHbdX4R","colab_type":"text"},"cell_type":"markdown","source":["*   cuda.is_available  = [Link](https://pytorch.org/docs/stable/cuda.html#torch.cuda.is_available)\n","*   device = [Link](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.device)\n","\n"]},{"metadata":{"id":"sPOF_Bqdd-kc","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"dlIy9LgbbR3L","colab_type":"code","colab":{}},"cell_type":"code","source":["# Play around with the hyperparams below\n","# Hyper parameters\n","num_epochs = 5\n","num_classes = 10\n","batch_size = 100\n","learning_rate = 0.001"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rgLQzhWycoE3","colab_type":"code","colab":{}},"cell_type":"code","source":["# The dataset we are going to work on is MNIST handwritten characters dataset.\n","# Follow the api in the below link to load the MNIST dataset in torchvision.datasets\n","# train_loader and test_loader need to use the dataloader api to have a batch wise data loading function\n","# Try to understand how batch wise training works by thinking about how training was done in the previous ML experiements "],"execution_count":0,"outputs":[]},{"metadata":{"id":"wXifFff7536M","colab_type":"text"},"cell_type":"markdown","source":["*   torchvision.datasets.MNIST = [Link](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist)\n","*   torch.utils.data.DataLoader = [Link](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n"]},{"metadata":{"id":"j9SyvqvJbgy2","colab_type":"code","colab":{}},"cell_type":"code","source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","# MNIST dataset\n","# Checkout possible transforms. Data augmentation can help improve accuracy in most cases.\n","# Explore any of the options available. Try to understand what they all do\n","train_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                           train=True, \n","                                           transform=##Enter code here##,\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='../../data/',\n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Try to add a cell below to see how the batch loader outputs data\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=##Enter code here##,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"--9iRR0u70yT","colab_type":"text"},"cell_type":"markdown","source":["Lets try to build  the network architecture from the given image.\n","\n","\n","1st layer:\n","\n","Convolution layer:\n","\n",">in_channels = 1\n",">out_channels = 16\n",">kernel_size = 5\n",">stride = 1\n",">padding = 2\n","\n","Batchnorm features = 16\n","\n","Maxpool layer:\n","\n",">kernel size= 2\n",">stride = 2\n"," \n"," \n","2nd layer:\n","\n","Convolution layer:\n","\n",">in_channels = 16\n",">out_channels = 32\n",">kernel_size = 5\n",">stride = 1\n",">padding = 2\n","\n","Batchnorm features = 32\n","\n","Maxpool layer:\n","\n",">kernel size= 2\n",">stride = 2\n"," "]},{"metadata":{"id":"OpOcpqc97qJx","colab_type":"text"},"cell_type":"markdown","source":["![alt text](https://pytorch.org/tutorials/_images/mnist.png)"]},{"metadata":{"id":"t5_OmAtxbjwV","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn as nn\n","\n","# Convolutional neural network (two convolutional layers)\n","# What does each layer do? Try to understand the significance of each operation\n","class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(##Enter code here##),\n","            nn.BatchNorm2d(##Enter code here##),\n","            nn.ReLU(),\n","            nn.MaxPool2d(##Enter code here##))\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(##Enter code here##),\n","            nn.BatchNorm2d(##Enter code here##),\n","            nn.ReLU(),\n","            nn.MaxPool2d(##Enter code here##))\n","        self.fc = nn.Linear(7*7*32, num_classes)\n","        \n","    def forward(self, x):\n","        ## Design the flow graph here\n","        # x here is the data\n","        # the transformations that need to be done are the 5 layers in sequence.\n","        # You might have to reshape the vector before the fully connected layers\n","        out = ##Enter the code here##\n","        return out\n","\n","model = ConvNet(num_classes).to(device)\n","print(model)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jo6mBtWPby2n","colab_type":"code","colab":{}},"cell_type":"code","source":["# Loss and optimizer\n","# WHat are the other losses that are available?\n","# Is cross entropy loss the best option?\n","# How should one choose the loss function?\n","# Ask TA or Professor, if you do not answers to these. Must know.\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"haa7Ttl5b60m","colab_type":"code","colab":{}},"cell_type":"code","source":["# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","      \n","        ## Pytorch has an easy method to convert data format to be compatible between CPU and GPU.\n","        # Convert the data vectors to the \"device\" type\n","        \n","        ## Enter the code here##        \n","        \n","        # Forward pass\n","        # Note how the output is extracted from the network in the line below.\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9wRKdgIPb_YV","colab_type":"code","colab":{}},"cell_type":"code","source":["# Test the model\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"85aUFT-WcGYX","colab_type":"code","colab":{}},"cell_type":"code","source":["# Save the model checkpoint\n","torch.save(model.state_dict(), 'model.ckpt')"],"execution_count":0,"outputs":[]}]}